procesos


La administración de procesos es una de las tareas más fundamentales y complejas de cualquier sistema operativo (SO) moderno. Su función principal es crear, gestionar y finalizar los procesos.
1. ¿Qué es un Proceso?
Un proceso es un concepto clave y fundamental en todos los sistemas operativos. En esencia, un proceso es un programa en ejecución.
El concepto de proceso va más allá de un simple programa, ya que un programa por sí mismo no hace nada a menos que sus instrucciones sean ejecutadas por una CPU. La ejecución de una aplicación corresponde a la existencia de uno o más procesos.
Un proceso se puede considerar como una unidad de actividad o la unidad de trabajo en un sistema. Es la entidad que puede ser asignada y ejecutada en un procesador.
Un proceso consiste en varios elementos esenciales:
Código de programa: Las instrucciones ejecutables del programa, que pueden ser compartidas con otros procesos que ejecuten el mismo programa.
Conjunto de datos asociados: Incluye variables, espacio de trabajo, buffers, y la pila.
Contexto de ejecución (o estado del proceso): Este es un conjunto de datos interno mediante el cual el sistema operativo supervisa y controla el proceso. Incluye el contenido de los registros del procesador (como el contador de programa y los registros de datos), la palabra de estado del programa (PSW), la prioridad, información de E/S pendiente, dispositivos asignados, archivos en uso, entre otros.
Toda esta información necesaria para gestionar el proceso se almacena en una estructura de datos llamada Bloque de Control de Proceso (BCP). El BCP es la estructura de datos más importante del sistema operativo y su conjunto define el estado del sistema.
Además, cada proceso tiene asociado un espacio de direcciones, que es el rango de ubicaciones de memoria donde el proceso puede leer y escribir información.
En un sistema, puede haber procesos del sistema operativo (que ejecutan código del sistema) y procesos de usuario (que ejecutan código de usuario). Todos estos procesos pueden ejecutarse concurrentemente.
2. Diferencia entre Proceso y Tarea (Task)
Las fuentes indican que el término "proceso" es un término más general que "trabajo" (job). En muchos contextos, "tarea" (task) es sinónimo de "proceso".
Sin embargo, el concepto de proceso es más complejo y sutil de lo que se presenta inicialmente, y en realidad, contiene dos conceptos diferentes y potencialmente independientes:
Propiedad de recursos: Un proceso incluye un espacio de direcciones virtuales, así como la propiedad o control de recursos como memoria principal, canales y dispositivos de E/S, y archivos. El sistema operativo se encarga de la protección para evitar interferencias entre procesos relacionadas con estos recursos.
Planificación/ejecución: Se refiere a la ruta de ejecución (traza) a través de uno o más programas, que puede entrelazarse con otros procesos. Un proceso tiene un estado de ejecución (Ejecutando, Listo, etc.) y una prioridad de activación, siendo esta la entidad que es planificada y activada por el sistema operativo.
Cuando estas dos características se tratan de forma independiente, la unidad que se activa (la unidad de ejecución) se denomina comúnmente hilo (thread), o proceso ligero, mientras que la unidad de propiedad de recursos se sigue denominando proceso o tarea. Un solo proceso puede contener múltiples hilos.
En el contexto de Linux, no se hace una distinción estricta entre proceso e hilo a nivel interno. El kernel de Linux representa a los procesos y a los hilos como "tareas" utilizando la estructura task_struct. Por lo tanto, un proceso con un solo hilo se representa como una estructura de tarea, y un proceso multihilo tendrá una estructura de tarea por cada uno de sus hilos a nivel de usuario. Incluso el propio kernel es multihilo, con hilos que ejecutan código del kernel y no están asociados a ningún proceso de usuario.
3. Requisitos del Sistema Operativo para Manejar Procesos
La tarea fundamental de cualquier sistema operativo moderno es la gestión de procesos. Para lograr esto, el sistema operativo debe cumplir varios requisitos clave:
Intercalado (Gestión de la Concurrencia):


El sistema operativo debe intercalar la ejecución de múltiples procesos para maximizar la utilización del procesador y proporcionar un tiempo de respuesta razonable. Esta es la base de la multiprogramación.
En un sistema monoprocesador multiprogramado, los procesos se entrelazan en el tiempo para dar la apariencia de ejecución simultánea.
En un sistema multiprocesador, la ejecución de procesos no solo se intercala, sino que también es posible que múltiples procesos se ejecuten de forma simultánea (solapamiento). Esto es lo que se conoce como multiprocesamiento.
Para esto, el SO necesita un planificador de procesos (o de hilos) que decide qué proceso se ejecutará a continuación y por cuánto tiempo.
Administración de Recursos:


Los procesos necesitan recursos como tiempo de CPU, memoria, archivos y dispositivos de E/S para realizar sus tareas.
El SO debe reservar y asignar estos recursos a los procesos.
Debe gestionar las demandas que planteen conflictos y asignar los recursos del sistema de acuerdo con una política específica (ej., prioridades).
El SO debe proteger los datos y recursos físicos de cada proceso de interferencias involuntarias de otros procesos. Esto incluye técnicas de gestión de memoria y control de acceso a archivos y dispositivos.
Comunicación y Sincronización:


El sistema operativo puede requerir dar soporte a la comunicación entre procesos (IPC - Interprocess Communication). Esto es crucial para la estructuración de aplicaciones y para la cooperación entre procesos.
También debe ser capaz de la sincronización de actividades de múltiples procesos.
Los mecanismos para la comunicación y sincronización incluyen semáforos, monitores, paso de mensajes, y tuberías (pipes).
El SO debe resolver problemas de concurrencia, como las condiciones de carrera (cuando múltiples procesos acceden a datos compartidos y el resultado depende del orden de ejecución), la exclusión mutua (asegurando que solo un proceso a la vez acceda a una sección crítica), y el interbloqueo (deadlock).
Modos de Ejecución (Modo Usuario/Supervisor):


Para gestionar procesos y proteger los recursos, los procesadores proporcionan al menos dos modos de ejecución: modo usuario y modo núcleo (o supervisor).
En modo núcleo, el sistema operativo tiene acceso completo a todo el hardware y puede ejecutar instrucciones privilegiadas (ej., E/S primitiva, modificar registros de control, gestión de memoria). Las regiones de memoria del SO son accesibles solo en este modo. El núcleo contiene las funciones del SO más frecuentemente utilizadas y es la única parte del sistema operativo que no es expulsable o paginable.
En modo usuario, los programas de aplicación y las utilidades se ejecutan con un subconjunto limitado de instrucciones y acceso restringido a la memoria. Si un programa de usuario intenta una operación privilegiada, se genera un error que transfiere el control al núcleo.
La interacción entre programas de usuario y el SO para acceder a sus servicios se realiza mediante llamadas al sistema (system calls). Una llamada al sistema es una instrucción especial que cambia el procesador del modo usuario al modo núcleo e inicia el sistema operativo para realizar la tarea solicitada. El mecanismo de interrupción es fundamental para esta transferencia de control.
Esta distinción de modos es esencial para la protección y seguridad del sistema, ya que protege al sistema operativo y sus estructuras de control de la interferencia de programas de usuario.
En síntesis, la gestión de procesos es el corazón de la funcionalidad de un sistema operativo, permitiéndole transformar un hardware complejo en una plataforma eficiente, segura y amigable para el usuario mediante la orquestación inteligente de la ejecución de programas, el uso de recursos y la interacción entre ellos.



Estados del proceso


La administración de procesos es una de las tareas fundamentales de cualquier sistema operativo moderno, y para llevarla a cabo, el sistema operativo (SO) necesita conocer y controlar el estado de cada proceso. Un proceso es una unidad de actividad caracterizada por una secuencia de ejecución, un estado actual y un conjunto de recursos del sistema asociados. El estado de un proceso define su actividad actual y su capacidad para ser ejecutado.
El SO utiliza el contexto de ejecución o estado del proceso para supervisar y controlar el proceso. Esta información, que incluye el identificador, estado, prioridad, contador de programa, punteros de memoria, datos de contexto, información de E/S y auditoría, se almacena en el Bloque de Control de Proceso (BCP).
Los modelos de estados de proceso han evolucionado para reflejar la creciente complejidad y eficiencia de los sistemas operativos multiprogramados.
1. Modelo de Dos Estados: Ejecutando y No Ejecutando
El modelo más simple posible para el comportamiento de un proceso considera que un proceso, en un instante dado, está siendo ejecutado por el procesador o no.
Ejecutando: El proceso está utilizando actualmente el procesador.
No Ejecutando: El proceso existe, es conocido por el sistema operativo, y está esperando su oportunidad de ejecutar.
Transiciones:
Cuando el SO crea un nuevo proceso, lo inserta en el sistema en estado No Ejecutando.
El proceso actualmente en ejecución puede interrumpirse, pasando de Ejecutando a No Ejecutando.
Un componente del SO, el activador (dispatcher), selecciona un proceso del estado No Ejecutando y lo cambia al estado Ejecutando.
Si un proceso finaliza o es abortado, se descarta del sistema.
Este modelo básico sugiere la necesidad de que el SO represente cada proceso (mediante el BCP) y mantenga una cola de procesos que no están ejecutando, esperando su turno.
2. Modelo de Cinco Estados: Nuevo, Listo, Ejecutando, Bloqueado y Saliente
El modelo de dos estados es insuficiente en un entorno multiprogramado, ya que no distingue entre procesos que están listos para ejecutarse y aquellos que están esperando por un evento (como una operación de E/S). Para abordar esto, el estado "No Ejecutando" se divide en "Listo" y "Bloqueado", y se añaden dos estados adicionales para gestionar el ciclo de vida completo del proceso.
Nuevo: El proceso acaba de ser creado pero aún no ha sido admitido en el grupo de procesos ejecutables por el sistema operativo. Típicamente, el BCP se ha creado, pero el programa y sus datos aún no se han cargado en la memoria principal.
Listo: Un proceso que está en la memoria principal y preparado para ejecutarse tan pronto como el procesador esté disponible.
Ejecutando: El proceso está actualmente utilizando el procesador. En un sistema uniprocesador, solo un proceso puede estar en este estado a la vez.
Bloqueado: Un proceso que está en la memoria principal pero no puede ejecutarse hasta que se cumpla un evento determinado o se complete una operación de E/S.
Saliente: Un proceso que ha sido liberado del grupo de procesos ejecutables por el sistema operativo, ya sea porque ha finalizado su ejecución o ha sido abortado por alguna razón.
Transiciones (como se ilustra en la Figura 3.6 de la fuente):
Null → Nuevo: Se crea un nuevo proceso para ejecutar un programa.
Nuevo → Listo: El sistema operativo mueve un proceso al estado Listo cuando está preparado para ejecutar y las condiciones del sistema (ej. límites de procesos, memoria disponible) lo permiten.
Listo → Ejecutando: El planificador a corto plazo (dispatcher) selecciona un proceso del estado Listo para que use el procesador.
Ejecutando → Saliente: El proceso finaliza su ejecución de forma normal o es abortado por el SO.
Ejecutando → Listo: El proceso en ejecución es interrumpido (ej., por un temporizador o por un proceso de mayor prioridad) y vuelve a la cola de Listo.
Ejecutando → Bloqueado: El proceso en ejecución necesita esperar por un evento (ej., E/S) y se mueve al estado Bloqueado.
Bloqueado → Listo: El evento por el que el proceso estaba esperando ocurre, y el proceso se mueve a la cola de Listo, quedando disponible para su ejecución.
El SO mantiene colas separadas para los procesos Listos y Bloqueados, o múltiples colas de Bloqueados, una por cada tipo de evento.
3. Suspensión de Procesos y sus Transiciones (Modelos de 6 y 7 Estados)
El modelo de cinco estados es adecuado, pero asume que todos los procesos (Listo, Ejecutando, Bloqueado) residen en la memoria principal. Sin embargo, en sistemas sin memoria virtual o en situaciones de baja memoria, puede ser necesario mover procesos de la memoria principal al almacenamiento secundario (disco) para liberar espacio. Esta acción se conoce como intercambio (swapping) o suspensión de procesos.
Un proceso suspendido se define por las siguientes características:
No está inmediatamente disponible para su ejecución.
Puede estar esperando un evento o no.
Fue puesto en este estado por un agente (el proceso, el padre o el SO) para prevenir su ejecución.
No puede ser reactivado hasta que el agente lo indique explícitamente.
Razones para la suspensión:
Intercambio (Swapping): La razón más importante. Si la memoria principal está llena y hay muchos procesos bloqueados, el SO puede suspender un proceso para liberar espacio y cargar otro.
Temporización: Un proceso que se ejecuta periódicamente puede suspenderse mientras espera su siguiente intervalo de ejecución.
Solicitud del proceso padre: Un proceso padre puede suspender a un hijo para examinarlo, modificarlo o coordinar sus actividades.
Propósito del SO: Para monitorización, auditoría, detección de interbloqueos u otros problemas del sistema.
La suspensión lleva a una revisión de los estados. Ahora se distinguen dos conceptos independientes: si un proceso está esperando un evento (bloqueado o no) y si un proceso está transferido de memoria a disco (suspendido o no).
Modelo de 6 estados (con un único estado Suspendido): Una forma conceptual de incorporar la suspensión es añadir un estado "Suspendido" general (Figura 3.9a de la fuente). Este estado engloba cualquier proceso que ha sido expulsado de la memoria principal, independientemente de si estaba "Listo" o "Bloqueado" antes de la suspensión. Sin embargo, para mayor precisión, es más útil distinguirlos.


Modelo de 7 Estados (Listo/Suspendido y Bloqueado/Suspendido): Este modelo divide el estado "Suspendido" en dos, reflejando el estado anterior del proceso.


Listo/Suspendido: El proceso está en almacenamiento secundario, pero está listo para ejecutar tan pronto como se cargue de nuevo en memoria principal [67, 69b].
Bloqueado/Suspendido: El proceso está en almacenamiento secundario y está esperando que se cumpla un evento. No podrá ejecutarse incluso si se carga en memoria principal hasta que el evento suceda [67, 69b].
Nuevas Transiciones (como se ilustra en la Figura 3.9b de la fuente):
Bloqueado → Bloqueado/Suspendido: Si no hay suficientes procesos Listos en memoria, el SO puede suspender un proceso Bloqueado para liberar espacio para otros procesos.
Listo → Listo/Suspendido: El SO puede decidir suspender un proceso Listo de la memoria principal, generalmente para reducir el grado de multiprogramación y evitar el thrashing o liberar recursos [69b].
Bloqueado/Suspendido → Listo/Suspendido: El evento por el que un proceso estaba esperando ocurre mientras este estaba suspendido. El proceso sigue en disco, pero ahora está Listo para ser reactivado [69b].
Bloqueado/Suspendido → Bloqueado: (Transición no explícitamente marcada en 3.9b como directa, pero implícita como reactivación). Un proceso Bloqueado/Suspendido se carga de nuevo en memoria principal pero aún espera el evento [69b].
Listo/Suspendido → Listo: Un proceso Listo/Suspendido se carga de nuevo en memoria principal y se vuelve disponible para ser planificado [69b].
Nuevo → Listo/Suspendido: Un nuevo proceso puede ser creado y colocado directamente en disco si no hay suficiente memoria principal disponible o si la política de creación lo prefiere.
Modelos más complejos (Ej. UNIX SVR4)
Sistemas operativos reales como UNIX SVR4 utilizan incluso más estados para describir el comportamiento de los procesos, totalizando nueve estados. Estos incluyen distinciones adicionales como:
Dos estados Ejecutando: para indicar si el proceso está ejecutando en modo usuario o en modo núcleo.
Un estado Expulsado: para procesos que ejecutan en modo núcleo (ej., por una llamada al sistema) y que son interrumpidos en favor de otro proceso de mayor prioridad.
Estos modelos de estados y sus transiciones son esenciales para que el sistema operativo pueda realizar la planificación de procesos, la asignación de recursos, la gestión de la memoria y la sincronización, garantizando el control y la eficiencia en un entorno multiprogramado.



Estructuras de datos asociadas
Para que un sistema operativo (SO) pueda cumplir con su tarea fundamental de gestionar procesos y recursos de manera eficiente y segura, necesita mantener una gran cantidad de información sobre el estado actual de cada proceso y cada recurso. Esto lo logra mediante el uso de diversas estructuras de control y tablas de datos.
1. Tablas del Sistema Operativo
El enfoque universal para que el SO mantenga esta información es construyendo y manteniendo tablas de información sobre cada entidad que gestiona. Aunque los detalles pueden variar entre sistemas operativos, todos ellos mantienen fundamentalmente información en cuatro categorías principales:
Tablas de Memoria: Se utilizan para llevar un registro de la memoria principal (real) y la memoria secundaria (virtual). Incluyen información sobre:
La asignación de memoria principal a los procesos.
La asignación de memoria secundaria a los procesos.
Los atributos de protección que restringen el uso de la memoria para que los procesos puedan acceder a áreas de memoria compartida.
La información necesaria para gestionar la memoria virtual.
Tablas de E/S (Entrada/Salida): Se usan para gestionar los dispositivos de E/S y los canales del computador. Incluyen:
El estado de los dispositivos (disponible o asignado).
El proceso al que está asignado un dispositivo.
El estado de las operaciones de E/S y las direcciones de memoria principal para las transferencias de datos.
Tablas de Ficheros: Proporcionan información sobre la existencia de ficheros, su ubicación en el almacenamiento secundario, su estado actual y otros atributos. Gran parte de esta información puede ser gestionada por un sistema de ficheros, que puede ser parte del SO o una utilidad del sistema.
Tablas de Procesos: Contienen la información necesaria para gestionar los procesos. Una tabla primaria de procesos puede tener una entrada por cada proceso y contener, al menos, un puntero a la imagen del proceso.
Es importante destacar que estas tablas están interconectadas y referenciadas entre sí. Por ejemplo, los ficheros se gestionan en nombre de los procesos, por lo que debe haber referencias a ellos en las tablas de procesos.
2. Imagen del Proceso
La imagen del proceso es la representación física de un proceso y agrupa todos los elementos necesarios para su ejecución. Como mínimo, un proceso incluye un programa o conjunto de programas a ejecutar, así como posiciones de memoria para datos (variables locales y globales, constantes).
Los elementos típicos de la imagen de un proceso son:
Datos del usuario: La parte modificable del espacio de usuario, que puede incluir datos del programa, el área de pila de usuario y programas que puedan ser modificados.
Programa de usuario (Texto): El código ejecutable del programa. En UNIX/Linux, es un área de solo lectura.
Pila de sistema: Cada proceso tiene una o más pilas de sistema (LIFO) asociadas a él, utilizadas para almacenar parámetros, direcciones de retorno de procedimientos y llamadas al sistema. En Windows, un hilo tiene dos pilas de llamadas separadas, una para el modo usuario y otra para el modo kernel.
Bloque de Control de Proceso (BCP): Contiene los datos que el sistema operativo necesita para controlar el proceso.
La ubicación de la imagen del proceso depende del esquema de gestión de memoria. En el caso más simple, se mantiene como un bloque de memoria contiguo, habitualmente en disco. Sin embargo, los sistemas operativos modernos con paginación permiten que la imagen del proceso se encuentre parcialmente en memoria principal y parcialmente en memoria secundaria (disco), lo que implica que sus partes no tienen que estar localizadas de forma contigua.
3. Bloque de Control de Proceso (BCP)
El Bloque de Control de Proceso (BCP), también conocido como descriptor de proceso o bloque de control de tarea, es la estructura de datos más importante en un sistema operativo. Contiene toda la información sobre un proceso que necesita el SO para gestionarlo.
La información en el BCP es suficiente para interrumpir un proceso en ejecución y luego reanudar su ejecución como si la interrupción no hubiera ocurrido. Virtualmente, cada módulo del SO (planificación, asignación de recursos, procesamiento de interrupciones, monitorización del rendimiento) lee y/o modifica los BCP. El conjunto de BCPs define el estado del sistema operativo.
Los elementos del BCP se pueden agrupar en tres categorías generales:
a) Información de Identificación del Proceso
Esta información se utiliza para identificar el proceso de forma única dentro del sistema.
Identificador del proceso (PID): Un número único asignado a cada proceso.
Identificador del proceso padre: Si el proceso fue creado por otro, se registra el ID del proceso que lo creó.
Identificador del usuario: El ID del usuario propietario del proceso.
b) Información del Estado del Procesador
Esta es la información esencial para que el SO pueda restaurar el contexto de un proceso cuando se le asigna el procesador.
Registros visibles por el usuario: Registros a los que el lenguaje máquina puede hacer referencia cuando el procesador está en modo usuario (ej., registros de datos, índices).
Registros de estado y control: Incluyen:
Contador de programa (PC): La dirección de la siguiente instrucción a ejecutar.
Códigos de condición: Resultados de la última operación lógica o aritmética (ej., signo, cero, acarreo, desbordamiento).
Información de estado: Incluye flags como interrupciones habilitadas/deshabilitadas y el modo de ejecución.
Puntero de pila: Apunta a la parte más alta de la pila de sistema asociada al proceso.
c) Información de Control del Proceso
Esta categoría, a menudo la más extensa, incluye la información adicional que el sistema operativo necesita para controlar y coordinar los diversos procesos activos. Abarca:
Información de estado y de planificación: Es la información que el SO necesita para las funciones de planificación. Incluye:
Estado del proceso: El estado actual del proceso (Ejecutando, Listo, Bloqueado, etc.).
Prioridad: El nivel de prioridad del proceso con respecto a otros.
Evento: Identificador del evento por el cual el proceso está esperando para continuar su ejecución (si está bloqueado).
Punteros a memoria: Punteros al código de programa, datos asociados y cualquier bloque de memoria compartido con otros procesos.
Datos de contexto: Datos presentes en los registros del procesador cuando el proceso está ejecutando.
Tiempo de procesador y tiempo de reloj utilizados: Información de auditoría.
Estructuración de datos: Punteros que permiten enlazar BCPs, implementando colas (ej., cola de listos, colas de bloqueados) o relaciones padre-hijo.
Comunicación entre procesos (IPC): Flags, señales y mensajes asociados a la comunicación entre procesos independientes pueden mantenerse en el BCP.
Privilegios de proceso: Los privilegios del proceso en cuanto a la memoria a la que puede acceder y los tipos de instrucciones que puede ejecutar, así como para el uso de utilidades o servicios del sistema.
Gestión de memoria: Punteros a tablas de segmentos y/o páginas que describen la memoria virtual asignada a este proceso.
Propiedad de recursos y utilización: Información sobre los recursos controlados por el proceso (ej., ficheros abiertos, dispositivos de E/S asignados) y un historial de uso de CPU u otros recursos.
Interrelaciones y Desafíos
Las tablas del sistema operativo y los BCPs están profundamente interconectados. Un identificador de proceso único puede utilizarse para indexar una tabla principal de procesos, que a su vez contiene punteros a las imágenes de los procesos. Los BCPs pueden contener punteros a otras estructuras de datos o segmentos, como los que contienen información sobre archivos abiertos o espacios de direcciones virtuales.
La necesidad de acceder y modificar los BCPs por casi todos los módulos del SO presenta desafíos:
Vulnerabilidad: Un fallo en una rutina del SO puede dañar los BCPs, comprometiendo la capacidad del sistema para gestionar procesos.
Coherencia: Un cambio en la estructura del BCP puede afectar a muchos módulos del SO.
Para mitigar estos problemas, se puede requerir que todas las rutinas del SO pasen a través de una rutina manejadora central que proteja los BCPs y arbitre las operaciones de lectura y escritura.
En resumen, las estructuras de datos asociadas, particularmente las tablas del sistema operativo y el Bloque de Control de Proceso, son la base sobre la cual el SO construye la abstracción de procesos, gestiona la concurrencia, asigna recursos, asegura la protección y permite la comunicación, haciendo posible el funcionamiento de los sistemas multiprogramados modernos.



Cambios de modo y cambio de proceso


Para comprender el funcionamiento interno de un sistema operativo (SO) moderno y su capacidad para gestionar múltiples programas de forma simultánea o intercalada, es fundamental entender los conceptos de cambio de modo y cambio de proceso, así como sus diferencias y el momento en que ocurren.
1. Cambio de Modo (Mode Switch)
El cambio de modo es una operación que implica la transición del procesador entre diferentes modos de ejecución. Los procesadores modernos suelen proporcionar al menos dos modos: el modo usuario y el modo núcleo (o supervisor).
Modo Núcleo (o Supervisor): En este modo, el sistema operativo tiene acceso completo a todo el hardware y puede ejecutar instrucciones privilegiadas. Estas incluyen la lectura y modificación de registros de control (como la palabra de estado del programa), instrucciones de entrada/salida (E/S) primitivas, e instrucciones relacionadas con la gestión de memoria. Además, ciertas regiones de memoria solo son accesibles en este modo más privilegiado.
Modo Usuario: En contraste, los programas de aplicación y utilidades se ejecutan en modo usuario, donde solo se permite un subconjunto limitado de instrucciones y el acceso a ciertas áreas de memoria está restringido.
Un cambio de modo se produce, por ejemplo, cuando un programa de usuario necesita un servicio del sistema operativo y realiza una llamada al sistema. Esta llamada es una instrucción especial que se puede invocar en modo usuario y que transfiere el control al núcleo, cambiando así el modo de ejecución del procesador.
El cambio de modo es un concepto distinto del cambio de proceso. Puede ocurrir sin que se cambie el estado del proceso que se está ejecutando actualmente. En estos casos, el guardado y la restauración del contexto implican poca sobrecarga. Un proceso puede estar ejecutando en modo usuario, hacer una llamada al sistema, y el procesador pasa a modo núcleo para ejecutar la rutina del SO, pero la ejecución sigue siendo dentro del mismo proceso de usuario. Así, no hay un cambio de proceso, sino un cambio de modo dentro del mismo proceso.
2. Cambio de Proceso (Process Switch)
Un cambio de proceso es la operación mediante la cual el procesador se transfiere de un proceso a otro. Esto implica guardar el estado completo del proceso actual y reemplazarlo con la información del siguiente proceso a ejecutar. Es una operación fundamental para la multiprogramación, donde la ejecución de varios procesos se intercala en el tiempo para dar la apariencia de ejecución simultánea en un monoprocesador.
El estado completo del proceso en un instante dado se encuentra en su contexto de ejecución, que el sistema operativo guarda en el Bloque de Control de Proceso (BCP). El BCP contiene toda la información necesaria para gestionar el proceso, incluyendo su estado actual, la reserva de recursos, la prioridad y otros datos relevantes. La imagen del proceso, que incluye el espacio de direcciones, el código del programa, los datos y la pila, también forma parte de lo que se gestiona en un cambio de proceso.
3. Diferencia entre Cambio de Modo y Cambio de Contexto
Es crucial diferenciar estos términos, ya que en la literatura a veces se utilizan de forma ambigua.
El cambio de modo ocurre cuando el procesador cambia entre el modo usuario y el modo núcleo, sin necesariamente cambiar el proceso que está utilizando la CPU. Su sobrecarga es relativamente baja.
El término cambio de contexto (context switch) es usado en la literatura de sistemas operativos. Sin embargo, puede referirse a un cambio de proceso, a un cambio de modo, o incluso a un cambio de hilo. Para evitar ambigüedades, en este libro se ha preferido utilizar el término cambio de proceso. En esencia, cuando la fuente menciona "cambio de contexto" en el contexto de pasar de un programa a otro, se refiere a lo que aquí denominamos cambio de proceso.
La diferencia clave en la sobrecarga es que un cambio de modo implica poco trabajo de guardado y restauración, mientras que un cambio de proceso requiere un esfuerzo mucho mayor, ya que implica actualizar el BCP del proceso actual, seleccionar uno nuevo, y restaurar su contexto completo, lo cual puede incluir vaciar cachés y modificar registros de asignación de memoria, operaciones que son costosas.
4. Cuándo se Produce una Conmutación (Cambio de Proceso)
Un cambio de proceso puede ocurrir en cualquier instante en que el sistema operativo obtiene el control sobre el proceso que está actualmente en ejecución. Las situaciones comunes que disparan una conmutación incluyen:
Interrupción por temporizador: En sistemas multiprogramados, el SO impone una restricción de tiempo a los procesos. Si un proceso en ejecución agota su "rodaja de tiempo" (time slice), el SO lo interrumpe y lo vuelve al estado Listo.
Evento de E/S: Si un proceso en ejecución necesita esperar por un evento de entrada/salida (E/S) (ej., leer del disco), se mueve al estado Bloqueado y el SO puede planificar otro proceso.
Llamada al sistema: Un proceso puede realizar una llamada al sistema para pedir un servicio que requiera esperar por un recurso o un evento. Esto lleva al proceso al estado Bloqueado y permite que el SO planifique otro.
Proceso de mayor prioridad listo: Si un proceso de mayor prioridad se vuelve Listo (ej., porque terminó su E/S o se le activó), el SO puede expulsar al proceso en ejecución y darle la CPU al de mayor prioridad.
Creación de un nuevo proceso: Cuando se crea un nuevo proceso (sea al arrancar el sistema, por petición de usuario, inicio de un trabajo por lotes o por un proceso existente), el SO debe decidir si ejecuta el proceso padre o el proceso hijo, o si planifica otro.
Terminación de un proceso: Cuando un proceso finaliza su ejecución de forma normal o es abortado, sale del sistema, y el SO debe seleccionar un nuevo proceso para ejecutar.
5. Pasos en un Cambio de Proceso
Cuando el sistema operativo decide realizar un cambio de proceso completo (es decir, el proceso actualmente en ejecución se va a mover a otro estado como Listo, Bloqueado o Saliente), sigue una serie de pasos sustanciales:
Salvar el estado del procesador: Esto incluye el contador de programa y todos los demás registros del procesador. Generalmente, esta operación la realiza el hardware.
Actualizar el bloque de control del proceso (BCP) actual: Se cambia el estado del proceso a uno de los otros estados (Listo, Bloqueado, Listo/Suspendido o Saliente). También se actualizan otros campos importantes, como la razón por la cual el proceso ha dejado el estado Ejecutando y la información de auditoría.
Mover el BCP a la cola apropiada: El BCP se coloca en la cola correspondiente a su nuevo estado (ej., cola de Listos, cola de Bloqueados en el evento X, o cola de Listo/Suspendido).
Selección de un nuevo proceso a ejecutar: El planificador del sistema operativo elige el siguiente proceso que pasará al estado Ejecutando.
Actualizar el BCP del proceso elegido: Se cambia el estado de este proceso a Ejecutando.
Actualizar las estructuras de datos de gestión de memoria: Dependiendo de cómo se realice la traducción de direcciones, puede ser necesario actualizar las tablas de paginación o segmentación u otras estructuras de memoria para reflejar el nuevo proceso en ejecución.
Restaurar el estado del procesador: Se cargan los valores anteriores del contador de programa y otros registros desde el BCP del proceso seleccionado, lo que permite que el nuevo proceso reanude su ejecución desde donde se quedó.
Estos pasos aseguran que el sistema operativo puede gestionar de manera efectiva la concurrencia y la asignación de la CPU entre los diferentes procesos, a pesar de la sobrecarga que implica cada conmutación completa.

Diseño y modos de ejecución del sistema operativo


Los modos de ejecución y la estructura de diseño de un sistema operativo (SO) son fundamentales para su funcionamiento, permitiéndole gestionar procesos, recursos y garantizar la seguridad. El SO puede ejecutar sus funciones de distintas maneras, lo que impacta en su rendimiento, flexibilidad y fiabilidad.
1. Ejecución como Kernel (Modo Privilegiado o Supervisor)
El modo núcleo (también conocido como modo sistema, modo control o modo privilegiado) es el entorno de ejecución más privilegiado dentro de un sistema informático. Es el modo en el que opera la pieza fundamental del software, el sistema operativo.
Características y Capacidades:
Acceso completo al hardware: El SO en modo núcleo tiene acceso total a todos los componentes del hardware de la computadora, incluyendo CPU, memoria y dispositivos de E/S.
Instrucciones privilegiadas: Puede ejecutar cualquier instrucción que la máquina sea capaz de realizar, incluyendo instrucciones especiales que están prohibidas para los programas en modo usuario. Estas instrucciones privilegiadas incluyen:
Lectura y modificación de registros de control (como la palabra de estado del programa o PSW).
Instrucciones de E/S primitivas.
Instrucciones relacionadas con la gestión de memoria.
La instrucción de detención (halt instruction).
Acceso a memoria protegida: Solo en modo núcleo se puede acceder a ciertas regiones de memoria, incluyendo las estructuras de datos clave del sistema operativo, como los Bloques de Control de Proceso (BCP).
Funciones del núcleo: El núcleo (kernel) es la porción del sistema operativo que se mantiene permanentemente en memoria principal y contiene las funciones más frecuentemente utilizadas. Este núcleo ejecuta en modo privilegiado y es responsable de funciones críticas como:
Gestión de memoria.
Manejo de interrupciones y excepciones.
Operaciones de E/S.
Planificación de procesos e hilos.
Intercambio (swapping) de procesos.
Sincronización de multiprocesadores.
Ejemplos de componentes en modo núcleo:
En Windows: El Sistema Ejecutivo, el Núcleo (kernel), los controladores de dispositivo y los sistemas gráficos. El Gestor de E/S también se ejecuta en modo núcleo.
En Linux: El kernel controla el acceso de la CPU a los dispositivos y la unidad de administración de memoria. Sus drivers de dispositivo se ejecutan en modo kernel.
En Symbian OS: El nanokernel y el kernel de Symbian OS ejecutan en modo privilegiado, controlando los nanohilos.
Propósito: La principal razón para utilizar el modo núcleo es proteger el sistema operativo y sus tablas clave de la interferencia de los programas de usuario. Este nivel de control completo es esencial para la estabilidad y seguridad del sistema.
2. Ejecución dentro de Procesos de Usuario
Una alternativa al diseño donde el kernel es una entidad totalmente independiente es ejecutar gran parte del software del sistema operativo dentro del contexto de un proceso de usuario.
Concepto y Funcionamiento:
En esta visión, el sistema operativo se percibe como un conjunto de rutinas que el usuario invoca para realizar diferentes funciones, pero que se ejecutan dentro del entorno del proceso de usuario.
Cuando un proceso de usuario necesita un servicio del SO (ej. una llamada al sistema), ejecuta una instrucción especial (una "trampa" o "trap") que transfiere el control al núcleo y cambia el procesador a modo núcleo.
En ese momento, el código del kernel se ejecuta en modo núcleo, pero utilizando el espacio de direcciones y el contexto (incluyendo la pila del núcleo) del proceso de usuario que realizó la llamada. El proceso sigue siendo el mismo hilo, pero con más privilegios.
El contexto del proceso de usuario se guarda (registros de usuario en la pila del kernel) para poder restaurarlo al regresar al modo usuario.
Ejemplos: Esta visión es común en sistemas operativos de máquinas pequeñas como PCs y estaciones de trabajo. UNIX SVR4, por ejemplo, sigue este modelo, donde la mayoría del SO se ejecuta dentro del entorno del proceso de usuario. Linux también opera de esta manera, donde un hilo de usuario que realiza una llamada al sistema se atrapa en el kernel y continúa su ejecución con un mapa de memoria distinto y acceso completo a los recursos de la máquina.
Ventajas:
Simplifica la interacción para el programador de aplicaciones, ya que ve el SO como un conjunto de servicios accesibles.
Aunque el SO se ejecuta dentro del entorno del proceso de usuario, la distinción entre modo usuario y modo núcleo asegura que el usuario no pueda interferir con las rutinas del SO.
3. Compartición de Código y Datos del SO
La compartición de código y datos del sistema operativo es crucial para la eficiencia y la modularidad del sistema.
Compartición de Código (Programas):
El código de programa ejecutable puede ser compartido entre múltiples procesos que ejecuten el mismo programa. Esto es una optimización fundamental para ahorrar memoria.
En el modelo de ejecución del SO dentro de procesos de usuario, las rutinas del sistema operativo que se ejecutan en varios procesos de usuario son idénticas.
Bibliotecas de Enlace Dinámico (DLLs) en sistemas como Windows son ejemplos de código compartido que implementa funciones del SO de alto nivel.
Compartición de Datos:
Los procesos pueden compartir datos entre sí.
Memoria Compartida: Los sistemas operativos modernos ofrecen mecanismos para que los procesos compartan porciones de su espacio de direcciones. Esto puede hacerse mediante la asignación de páginas de memoria común en los espacios de direcciones virtuales de los procesos.
Área de Memoria Compartida en UNIX: En UNIX SVR4, existe un área de memoria compartida que se presenta a cada proceso que la comparte dentro de su propio espacio de dirección virtual, aunque solo existe una única copia física.
Objetos de Windows: Windows utiliza un diseño orientado a objetos que facilita la compartición de recursos y datos entre procesos. El Administrador de Objetos de Windows proporciona una interfaz uniforme para gestionar y compartir recursos y estructuras de datos del sistema, como secciones de memoria, archivos abiertos y semáforos. Los hilos de un mismo proceso pueden acceder a todos los objetos de su proceso, ya que no hay restricciones que impidan a un hilo acceder a un objeto abierto por otro hilo del mismo proceso.
Espacio de Direcciones del Kernel: En sistemas como Windows, casi todo el espacio de direcciones virtuales del kernel se comparte entre todos los procesos.
4. Sistemas Operativos Basados en Procesos (Arquitectura Microkernel)
Una tercera alternativa de diseño para la ejecución del sistema operativo es implementarlo como una colección de procesos de sistema. Esta arquitectura es fundamental para el concepto de micronúcleo.
Concepto:
En este modelo, las principales funciones del núcleo se organizan como procesos independientes.
Estos procesos de sistema, que implementan servicios como la gestión de memoria, el sistema de archivos y los controladores de dispositivo, se ejecutan en modo núcleo o en modo usuario como "servidores", interactuando con un núcleo muy pequeño.
El núcleo (microkernel) en sí solo contiene las funciones más esenciales y críticas, como la gestión de espacios de almacenamiento, la comunicación entre procesos (IPC) y la planificación básica. Una pequeña cantidad de código para el intercambio de procesos aún debe ejecutarse fuera de todos los procesos.
Ventajas del Diseño Basado en Procesos (Microkernel):
Modularidad y flexibilidad: Impone una disciplina de diseño que refuerza el uso de sistemas operativos modulares con interfaces mínimas y claras entre los módulos. Esto facilita la adición o modificación de servicios sin necesidad de reconstruir todo el núcleo.
Fiabilidad: Si un proceso de servidor falla (ej., un controlador de dispositivo o un servidor de archivos), el impacto en el resto del sistema es limitado, ya que los servicios se ejecutan en espacios de direcciones separados.
Soporte para sistemas distribuidos: Facilita la construcción de sistemas distribuidos, ya que los servicios del SO se pueden enviar a procesadores dedicados, aumentando el rendimiento y permitiendo la interacción uniforme con procesos locales y remotos.
Extensibilidad y portabilidad: El diseño modular hace que sea más fácil extender el sistema con nuevas características y portarlo a diferentes arquitecturas de hardware.
Desventajas (potenciales):
Rendimiento: Puede sufrir una penalización de rendimiento debido a la sobrecarga de la comunicación entre procesos (IPC) y los cambios de modo frecuentes entre los servidores en modo usuario y el microkernel en modo núcleo. Esto fue una razón para que Windows optara por una "arquitectura micronúcleo modificada" donde muchas funciones se ejecutan en modo núcleo para mejorar el rendimiento.
Ejemplos:
MINIX 3: Un sistema operativo parecido a UNIX basado en un microkernel, donde el administrador de memoria, el sistema de archivos y cada driver de dispositivo son procesos de usuario separados.
Symbian OS: Utiliza un diseño de microkernel con un "nanokernel" muy pequeño en su núcleo, y sus servicios del sistema se implementan como servidores en espacio de usuario.
En síntesis, la elección entre estas arquitecturas y modos de ejecución refleja compromisos entre rendimiento, seguridad, flexibilidad y facilidad de desarrollo, y ha evolucionado con la complejidad de los sistemas informáticos.

